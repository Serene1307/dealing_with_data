{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Categorizing and Tagging Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Back in elementary school you learnt the difference between nouns, verbs, adjectives, and adverbs. These are  very useful categories for many language processing tasks. Our goals chapter is to answer the following questions:\n",
    "\n",
    "1. What are lexical categories and how are they used in natural language processing?\n",
    "2. What is a good Python data structure for storing words and their categories?\n",
    "3. How can we automatically tag each word of a text with its word class?\n",
    "\n",
    "The process of classifying words into their parts of speech and labeling them accordingly is known as part-of-speech tagging, POS-tagging, or simply tagging. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Using a POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A part-of-speech tagger, or POS-tagger, processes a sequence of words, and attaches a part of speech tag to each word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text = nltk.word_tokenize(\"And now for something completely different\")\n",
    "\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we see that and is CC, a coordinating conjunction; now and completely are RB, or adverbs; for is IN, a preposition; something is NN, a noun; and different is JJ, an adjective.\n",
    "\n",
    "NLTK provides documentation for each tag, which can be queried using the tag, e.g. `nltk.help.upenn_tagset('RB')`, or a regular expression, e.g. `nltk.help.upenn_tagset('NN.*')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('VB.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's look at another example, this time including some **homonyms**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('refuse', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('permit', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('obtain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('refuse', 'NN'),\n",
       " ('permit', 'NN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\n",
    "nltk.pos_tag(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice that refuse and permit both appear as a present tense verb (VBP) and a noun (NN). E.g. refUSE is a verb meaning \"deny,\" while REFuse is a noun meaning \"trash\" (i.e. they are not homophones). Thus, we need to know which word is being used in order to pronounce the text correctly. (For this reason, text-to-speech systems usually perform POS-tagging.)\n",
    "\n",
    "See now how this information can be useful when trying to figure out the sense of a word in WordNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('garbage.n.01'),\n",
       " Synset('refuse.v.01'),\n",
       " Synset('refuse.v.02'),\n",
       " Synset('defy.v.02'),\n",
       " Synset('deny.v.04'),\n",
       " Synset('resist.v.05'),\n",
       " Synset('reject.v.06')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('refuse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma name: ['garbage', 'refuse', 'food_waste', 'scraps']\n",
      "Definition: food that is discarded (as from a kitchen)\n",
      "Examples  : []\n",
      "=======================\n",
      "Lemma name: ['refuse', 'decline']\n",
      "Definition: show unwillingness towards\n",
      "Examples  : ['he declined to join the group on a hike']\n",
      "=======================\n",
      "Lemma name: ['refuse', 'reject', 'pass_up', 'turn_down', 'decline']\n",
      "Definition: refuse to accept\n",
      "Examples  : ['He refused my offer of hospitality']\n",
      "=======================\n",
      "Lemma name: ['defy', 'resist', 'refuse']\n",
      "Definition: elude, especially in a baffling way\n",
      "Examples  : ['This behavior defies explanation']\n",
      "=======================\n",
      "Lemma name: ['deny', 'refuse']\n",
      "Definition: refuse to let have\n",
      "Examples  : ['She denies me every pleasure', 'he denies her her weekly allowance']\n",
      "=======================\n",
      "Lemma name: ['resist', 'reject', 'refuse']\n",
      "Definition: resist immunologically the introduction of some foreign tissue or organ\n",
      "Examples  : ['His body rejected the liver of the donor']\n",
      "=======================\n",
      "Lemma name: ['reject', 'turn_down', 'turn_away', 'refuse']\n",
      "Definition: refuse entrance or membership\n",
      "Examples  : ['They turned away hundreds of fans', 'Black people were often rejected by country clubs']\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "senses = [(s.lemma_names(), s.definition(), s.examples()) \n",
    "          for s in wn.synsets('refuse')]\n",
    "for s in senses:\n",
    "    print(\"Lemma name:\", s[0])\n",
    "    print(\"Definition:\", s[1])\n",
    "    print(\"Examples  :\", s[2])\n",
    "    print(\"=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "There is just one interpretation of _refuse_ that is a noun (garbage.n.01) and the most common interpretation of refuse as a verb means \"show unwillingness towards\" which is the correct interpretation in our context. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Exercise\n",
    "\n",
    "Many words, like ski and race, can be used as nouns or verbs with no difference in pronunciation. Can you think of others? Now make up a sentence with both uses of this word, and run the POS-tagger on this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('children', 'NNS'),\n",
       " ('had', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('run', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('get', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('run', 'VB'),\n",
       " ('on', 'IN'),\n",
       " ('time', 'NN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "text = nltk.word_tokenize(\"The children had to run to get to run on time\")\n",
    "tagged = nltk.pos_tag(text)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Representing Tagged Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "By convention in NLTK, a tagged token is represented using a **tuple** consisting of the token and the tag. We can create one of these special tuples from the standard string representation of a tagged token, using the function str2tuple():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('refuse', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('permit', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('obtain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('refuse', 'NN'),\n",
       " ('permit', 'NN')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\n",
    "tagged = nltk.pos_tag(text)\n",
    "tagged_token = tagged[0]\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('They', 'PRP')\n",
      "They\n",
      "PRP\n"
     ]
    }
   ],
   "source": [
    "print(tagged_token)\n",
    "print(tagged_token[0])\n",
    "print(tagged_token[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text =  ['They', 'refuse', 'to', 'permit', 'us', 'to', 'obtain', 'the', 'refuse', 'permit']\n",
      "Tokens =  ['They', 'refuse', 'to', 'permit', 'us', 'to', 'obtain', 'the', 'refuse', 'permit']\n"
     ]
    }
   ],
   "source": [
    "print(\"Text = \", text)\n",
    "tokens = [a for (a, b) in tagged]\n",
    "print(\"Tokens = \",tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags =  ['PRP', 'VBP', 'TO', 'VB', 'PRP', 'TO', 'VB', 'DT', 'NN', 'NN']\n"
     ]
    }
   ],
   "source": [
    "tags = [b for (a, b) in tagged]\n",
    "print(\"POS Tags = \", tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 6 samples and 10 outcomes>\n",
      " TO  VB PRP  NN  DT VBP \n",
      "  2   2   2   2   1   1 \n"
     ]
    }
   ],
   "source": [
    "fd = nltk.FreqDist(tags)\n",
    "print(fd)\n",
    "fd.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "tagged = nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NNP   NN    ,   IN  PRP    .   DT   JJ   VB   RB   CC PRP$    :  VBP  NNS  VBZ   TO  VBD   MD   ''  VBN   WP  WRB  POS  VBG  WDT   CD  JJS   EX  JJR NNPS  RBR   RP   UH    (    )  PDT  RBS  WP$   FW  SYM \n",
      "5217 4214 2892 2821 2463 2362 2263 1696 1538 1492 1295 1261  980  943  788  774  685  591  570  517  261  253  231  209  174  111   90   87   79   74   62   58   51   50   45   43   42   36   19   15    8 \n"
     ]
    }
   ],
   "source": [
    "tokens = [a for (a, b) in tagged]\n",
    "tags = [b for (a, b) in tagged]\n",
    "fd = nltk.FreqDist(tags)\n",
    "fd.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n",
    "tagged_wsj = nltk.pos_tag(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NN   NNP    IN    JJ    DT   NNS     ,    CD     .   VBD    RB    VB    CC    TO   VBZ   VBN   PRP   VBP   VBG    MD   POS  PRP$     $    ``    ''     :   JJR   WDT    WP    RP  NNPS   JJS   WRB   RBR    EX   RBS   PDT     #    FW   WP$    UH   SYM \n",
      "14666 10457 10055  8747  8117  6333  4885  4725  3874  3185  2875  2570  2312  2181  2036  1856  1712  1496  1396   930   852   771   726   712   693   563   359   250   244   216   182   179   177   142    91    35    27    16    15    14     3     1 \n"
     ]
    }
   ],
   "source": [
    "tokens_wsj = [a for (a, b) in tagged_wsj]\n",
    "tags_wsj = [b for (a, b) in tagged_wsj]\n",
    "fd_wsj = nltk.FreqDist(tags_wsj)\n",
    "fd_wsj.tabulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Exercise \n",
    "\n",
    "Load a text of your choice, tokenize it, and perform part of speech tagging on it. Then extract the nouns from the text, and perform a frequency anaysis, to identify the most common nouns in the text. (Warning: POS tagging takes a good amount of time when processing long texts, so try to select a text with less than 10K tokens, or simply perform POS tagging on the first 10K-20K tokens).\n",
    "\n",
    "Repeat the exercise for adjectives.\n",
    "\n",
    "PS: If you want to parse text from HTML without resorting to XPath expressions, you can use the \"BeautifulSoup\" library as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"http://www.nytimes.com/2014/11/11/world/asia/obama-apec-china-hong-kong.html\"\n",
    "resp = requests.get(url)\n",
    "html = resp.text \n",
    "raw = BeautifulSoup(html, \"lxml\").get_text()\n",
    "\n",
    "# The code below is to remove the junk that was extracted in addition to the article\n",
    "start = raw.index(u\"BEIJING —\")\n",
    "end = raw.index(u\"than Shanghai Tang.\")\n",
    "raw = raw[start:end]\n",
    "\n",
    "# Let's do the NLTK stuff\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "tagged = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BEIJING', 'NNP'),\n",
       " ('—', 'NNP'),\n",
       " ('President', 'NNP'),\n",
       " ('Obama', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('China', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('less', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('three', 'CD'),\n",
       " ('days', 'NNS'),\n",
       " ('this', 'DT'),\n",
       " ('week', 'NN'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('he', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('seeing', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('deal', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('President', 'NNP'),\n",
       " ('Xi', 'NNP'),\n",
       " ('Jinping.On', 'NNP'),\n",
       " ('Tuesday', 'NNP'),\n",
       " (',', ','),\n",
       " ('they', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('go', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('quiet', 'JJ'),\n",
       " ('walk', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Xi’s', 'NNP'),\n",
       " ('walled', 'VBD'),\n",
       " ('compound', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('have', 'VBP'),\n",
       " ('dinner', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('next', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " (',', ','),\n",
       " ('they', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('take', 'VB'),\n",
       " ('part', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('formal', 'JJ'),\n",
       " ('welcoming', 'NN'),\n",
       " ('ceremony', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Great', 'NNP'),\n",
       " ('Hall', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('People', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('toast', 'RB'),\n",
       " ('each', 'DT'),\n",
       " ('other', 'JJ'),\n",
       " ('at', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('state', 'NN'),\n",
       " ('banquet.Mr', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Obama', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('spend', 'VB'),\n",
       " ('far', 'RB'),\n",
       " ('less', 'JJR'),\n",
       " ('quality', 'JJ'),\n",
       " ('time', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('broader', 'JJR'),\n",
       " ('Chinese', 'JJ'),\n",
       " ('population', 'NN'),\n",
       " ('.', '.'),\n",
       " ('There', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('no', 'DT'),\n",
       " ('town-hall-style', 'JJ'),\n",
       " ('meetings', 'NNS'),\n",
       " (',', ','),\n",
       " ('televised', 'VBN'),\n",
       " ('interviews', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('major', 'JJ'),\n",
       " ('speeches', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('schedule.Much', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('was', 'VBD'),\n",
       " ('due', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('time', 'NN'),\n",
       " ('constraints', 'NNS'),\n",
       " (':', ':'),\n",
       " ('squeezing', 'VBG'),\n",
       " ('an', 'DT'),\n",
       " ('economic', 'JJ'),\n",
       " ('summit', 'NN'),\n",
       " ('meeting', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('state', 'NN'),\n",
       " ('visit', 'NN'),\n",
       " ('into', 'IN'),\n",
       " ('three', 'CD'),\n",
       " ('days', 'NNS'),\n",
       " (',', ','),\n",
       " ('before', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('president', 'NN'),\n",
       " ('leaves', 'VBZ'),\n",
       " ('on', 'IN'),\n",
       " ('Wednesday', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('travel', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('Myanmar', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Australia', 'NNP'),\n",
       " (',', ','),\n",
       " ('is', 'VBZ'),\n",
       " ('no', 'DT'),\n",
       " ('easy', 'JJ'),\n",
       " ('task', 'NN'),\n",
       " ('.', '.'),\n",
       " ('But', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('itinerary', 'NN'),\n",
       " ('also', 'RB'),\n",
       " ('reflects', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('White', 'NNP'),\n",
       " ('House’s', 'NNP'),\n",
       " ('decision', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('nurture', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('one-on-one', 'NN'),\n",
       " ('relationship', 'NN'),\n",
       " ('between', 'IN'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Obama', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Xi', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('favor', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('reaching', 'VBG'),\n",
       " ('out', 'RP'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('Chinese', 'JJ'),\n",
       " ('public', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Continue', 'VB'),\n",
       " ('reading', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('main', 'JJ'),\n",
       " ('story', 'NN'),\n",
       " ('Advertisement', 'NNP'),\n",
       " ('Continue', 'NNP'),\n",
       " ('reading', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('main', 'JJ'),\n",
       " ('story', 'NN'),\n",
       " ('The', 'DT'),\n",
       " ('White', 'NNP'),\n",
       " ('House', 'NNP'),\n",
       " ('has', 'VBZ'),\n",
       " ('learned', 'VBN'),\n",
       " ('that', 'IN'),\n",
       " ('those', 'DT'),\n",
       " ('efforts', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('often', 'RB'),\n",
       " ('stymied', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Chinese', 'JJ'),\n",
       " ('government', 'NN'),\n",
       " ('.', '.'),\n",
       " ('When', 'WRB'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Obama', 'NNP'),\n",
       " ('took', 'VBD'),\n",
       " ('part', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('town-hall', 'JJ'),\n",
       " ('meeting', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('first', 'JJ'),\n",
       " ('visit', 'NN'),\n",
       " ('here', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('president', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('2009', 'CD'),\n",
       " (',', ','),\n",
       " ('his', 'PRP$'),\n",
       " ('hosts', 'NNS'),\n",
       " ('tried', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('limit', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('audience', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('control', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('questions', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('They', 'PRP'),\n",
       " ('refused', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('stream', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('session', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Internet', 'NNP'),\n",
       " ('or', 'CC'),\n",
       " ('mention', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('evening', 'NN'),\n",
       " ('news', 'NN'),\n",
       " ('broadcasts', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Advertisement', 'NNP'),\n",
       " ('Continue', 'NNP'),\n",
       " ('reading', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('main', 'JJ'),\n",
       " ('story', 'NN'),\n",
       " ('These', 'DT'),\n",
       " ('restrictions', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('amplified', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('American', 'JJ'),\n",
       " ('news', 'NN'),\n",
       " ('media', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('cast', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('shadow', 'NN'),\n",
       " ('over', 'IN'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Obama’s', 'NNP'),\n",
       " ('trip', 'NN'),\n",
       " (',', ','),\n",
       " ('reinforcing', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('narrative', 'JJ'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('president', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('vulnerable', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('Chinese', 'JJ'),\n",
       " ('manipulation', 'NN'),\n",
       " ('.', '.'),\n",
       " ('White', 'NNP'),\n",
       " ('House', 'NNP'),\n",
       " ('officials', 'NNS'),\n",
       " ('said', 'VBD'),\n",
       " ('they', 'PRP'),\n",
       " ('got', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('audience', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('deemed', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('event', 'NN'),\n",
       " ('worthwhile', 'NN'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('endless', 'JJ'),\n",
       " ('haggling', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Chinese', 'JJ'),\n",
       " ('left', 'VBD'),\n",
       " ('them', 'PRP'),\n",
       " ('fed', 'VB'),\n",
       " ('up.The', 'JJ'),\n",
       " ('White', 'NNP'),\n",
       " ('House', 'NNP'),\n",
       " ('has', 'VBZ'),\n",
       " ('also', 'RB'),\n",
       " ('changed', 'VBN'),\n",
       " ('its', 'PRP$'),\n",
       " ('approach', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('Chinese', 'JJ'),\n",
       " ('news', 'NN'),\n",
       " ('media', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('2009', 'CD'),\n",
       " (',', ','),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Obama', 'NNP'),\n",
       " ('gave', 'VBD'),\n",
       " ('an', 'DT'),\n",
       " ('interview', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('Southern', 'NNP'),\n",
       " ('Weekly', 'NNP'),\n",
       " (',', ','),\n",
       " ('a', 'DT'),\n",
       " ('newspaper', 'NN'),\n",
       " ('based', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('Guangdong', 'NNP'),\n",
       " ('Province', 'NNP'),\n",
       " ('that', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('known', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('pushing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('limits', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('China’s', 'NNP'),\n",
       " ('censorship', 'NN'),\n",
       " ('rules', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('government', 'NN'),\n",
       " ('clumsily', 'RB'),\n",
       " ('censored', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('transcript', 'NN'),\n",
       " (',', ','),\n",
       " ('leaving', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Obama’s', 'NNP'),\n",
       " ('lighthearted', 'VBD'),\n",
       " ('observations', 'NNS'),\n",
       " ('about', 'IN'),\n",
       " ('basketball.This', 'NN'),\n",
       " ('time', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('White', 'NNP'),\n",
       " ('House', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('granting', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('written', 'VBN'),\n",
       " ('interview', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Obama', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('China’s', 'NNP'),\n",
       " ('official', 'NN'),\n",
       " ('news', 'NN'),\n",
       " ('agency', 'NN'),\n",
       " (',', ','),\n",
       " ('Xinhua', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('That', 'DT'),\n",
       " ('interview', 'NN'),\n",
       " (',', ','),\n",
       " ('combined', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('president’s', 'NN'),\n",
       " ('encounters', 'VBZ'),\n",
       " ('with', 'IN'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Xi', 'NNP'),\n",
       " (',', ','),\n",
       " ('ensures', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('visit', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('widely', 'RB'),\n",
       " ('covered', 'VBN'),\n",
       " ('here', 'RB'),\n",
       " (',', ','),\n",
       " ('officials', 'NNS'),\n",
       " ('said', 'VBD'),\n",
       " ('.', '.'),\n",
       " ('Advertisement', 'NNP'),\n",
       " ('Continue', 'NNP'),\n",
       " ('reading', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('main', 'JJ'),\n",
       " ('story', 'NN'),\n",
       " ('White', 'NNP'),\n",
       " ('House', 'NNP'),\n",
       " ('officials', 'NNS'),\n",
       " ('note', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('when', 'WRB'),\n",
       " ('Michelle', 'NNP'),\n",
       " ('Obama', 'NNP'),\n",
       " ('visited', 'VBD'),\n",
       " ('China', 'NNP'),\n",
       " ('last', 'JJ'),\n",
       " ('March', 'NNP'),\n",
       " ('with', 'IN'),\n",
       " ('her', 'PRP$'),\n",
       " ('daughters', 'NNS'),\n",
       " (',', ','),\n",
       " ('Malia', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Sasha', 'NNP'),\n",
       " (',', ','),\n",
       " ('they', 'PRP'),\n",
       " ('did', 'VBD'),\n",
       " ('plenty', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('public', 'JJ'),\n",
       " ('diplomacy', 'NN'),\n",
       " ('—', 'NNP'),\n",
       " ('playing', 'NN'),\n",
       " ('table', 'NN'),\n",
       " ('tennis', 'NN'),\n",
       " (',', ','),\n",
       " ('dabbling', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('calligraphy', 'NN'),\n",
       " (',', ','),\n",
       " ('practicing', 'VBG'),\n",
       " ('tai', 'NN'),\n",
       " ('chi', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('trudging', 'VBG'),\n",
       " ('up', 'RP'),\n",
       " ('the', 'DT'),\n",
       " ('Great', 'NNP'),\n",
       " ('Wall.Moreover', 'NNP'),\n",
       " (',', ','),\n",
       " ('they', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " (',', ','),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Obama', 'NNP'),\n",
       " ('did', 'VBD'),\n",
       " ('his', 'PRP$'),\n",
       " ('part', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('people-to-people', 'JJ'),\n",
       " ('relations', 'NNS'),\n",
       " (',', ','),\n",
       " ('announcing', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('reciprocal', 'JJ'),\n",
       " ('agreement', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('China', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('extend', 'VB'),\n",
       " ('tourist', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('business', 'NN'),\n",
       " ('visas', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('10', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('year', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('student', 'NN'),\n",
       " ('visas', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('five', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('deal', 'NN'),\n",
       " (',', ','),\n",
       " ('he', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('create', 'VB'),\n",
       " ('jobs', 'NNS'),\n",
       " (',', ','),\n",
       " ('make', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('easier', 'JJR'),\n",
       " ('for', 'IN'),\n",
       " ('businesspeople', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('invest', 'VB'),\n",
       " ('and', 'CC'),\n",
       " ('encourage', 'VB'),\n",
       " ('thousands', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('exchange', 'NN'),\n",
       " ('students', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Photo', 'NN'),\n",
       " ('From', 'IN'),\n",
       " ('left', 'VBN'),\n",
       " (',', ','),\n",
       " ('Hassanal', 'NNP'),\n",
       " ('Bolkiah', 'NNP'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('sultan', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Brunei', 'NNP'),\n",
       " (';', ':'),\n",
       " ('President', 'NNP'),\n",
       " ('Vladimir', 'NNP'),\n",
       " ('V.', 'NNP'),\n",
       " ('Putin', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Russia', 'NNP'),\n",
       " (';', ':'),\n",
       " ('President', 'NNP'),\n",
       " ('Xi', 'NNP'),\n",
       " ('Jinping', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('China', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('his', 'PRP$'),\n",
       " ('wife', 'NN'),\n",
       " (',', ','),\n",
       " ('Peng', 'NNP'),\n",
       " ('Liyuan', 'NNP'),\n",
       " (';', ':'),\n",
       " ('and', 'CC'),\n",
       " ('President', 'NNP'),\n",
       " ('Obama', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('ceremonial', 'JJ'),\n",
       " ('reception', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('Monday', 'NNP'),\n",
       " ('that', 'WDT'),\n",
       " ('was', 'VBD'),\n",
       " ('part', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('summit', 'NN'),\n",
       " ('meeting', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Beijing', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Credit', 'NNP'),\n",
       " ('Pool', 'NNP'),\n",
       " ('photo', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('Mikhail', 'NNP'),\n",
       " ('Klimentyev', 'NNP'),\n",
       " ('Advertisement', 'NNP'),\n",
       " ('Continue', 'NNP'),\n",
       " ('reading', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('main', 'JJ'),\n",
       " ('story', 'NN'),\n",
       " ('The', 'DT'),\n",
       " ('amount', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('time', 'NN'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Obama', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('willing', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('lavish', 'VB'),\n",
       " ('on', 'IN'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Xi', 'NNP'),\n",
       " ('attests', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('power', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('single', 'JJ'),\n",
       " ('Chinese', 'JJ'),\n",
       " ('citizen', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Xi’s', 'NNP'),\n",
       " ('status', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('nation’s', 'JJ'),\n",
       " ('paramount', 'NN'),\n",
       " ('leader', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('only', 'RB'),\n",
       " ('been', 'VBN'),\n",
       " ('enhanced', 'VBN'),\n",
       " ('since', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('two', 'CD'),\n",
       " ('men', 'NNS'),\n",
       " ('spent', 'VBD'),\n",
       " ('nearly', 'RB'),\n",
       " ('eight', 'CD'),\n",
       " ('hours', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('discussions', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('June', 'NNP'),\n",
       " ('2013', 'CD'),\n",
       " (',', ','),\n",
       " ('strolling', 'VBG'),\n",
       " ('amid', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('cactuses', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Sunnylands', 'NNP'),\n",
       " ('estate', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Rancho', 'NNP'),\n",
       " ('Mirage', 'NNP'),\n",
       " (',', ','),\n",
       " ('Calif.By', 'NNP'),\n",
       " ('contrast', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('White', 'NNP'),\n",
       " ('House', 'NNP'),\n",
       " ('played', 'VBD'),\n",
       " ('down', 'RP'),\n",
       " ('a', 'DT'),\n",
       " ('brief', 'JJ'),\n",
       " ('encounter', 'NN'),\n",
       " ('between', 'IN'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Obama', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('President', 'NNP'),\n",
       " ('Vladimir', 'NNP'),\n",
       " ('V.', 'NNP'),\n",
       " ('Putin', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Russia', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('opening', 'NN'),\n",
       " ('ceremony', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Asia-Pacific', 'JJ'),\n",
       " ('Economic', 'NNP'),\n",
       " ('Cooperation', 'NNP'),\n",
       " ('forum', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('Monday', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('two', 'CD'),\n",
       " ('leaders', 'NNS'),\n",
       " ('did', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('have', 'VB'),\n",
       " ('time', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('say', 'VB'),\n",
       " ('more', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('hello', 'NN'),\n",
       " (',', ','),\n",
       " ('an', 'DT'),\n",
       " ('official', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('.', '.'),\n",
       " ('Advertisement', 'NNP'),\n",
       " ('Continue', 'NNP'),\n",
       " ('reading', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('main', 'JJ'),\n",
       " ('story', 'NN'),\n",
       " ('The', 'DT'),\n",
       " ('White', 'NNP'),\n",
       " ('House', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('well', 'RB'),\n",
       " ('aware', 'JJ'),\n",
       " ('that', 'IN'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Obama’s', 'NNP'),\n",
       " ('encounters', 'VBZ'),\n",
       " ('with', 'IN'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Xi', 'NNP'),\n",
       " ('run', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('risk', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('looking', 'VBG'),\n",
       " ('stage-managed', 'JJ'),\n",
       " (',', ','),\n",
       " ('which', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('one', 'CD'),\n",
       " ('reason', 'NN'),\n",
       " ('American', 'JJ'),\n",
       " ('officials', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('pushing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('Chinese', 'JJ'),\n",
       " ('authorities', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('permit', 'VB'),\n",
       " ('questions', 'NNS'),\n",
       " ('when', 'WRB'),\n",
       " ('the', 'DT'),\n",
       " ('two', 'CD'),\n",
       " ('men', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('deliver', 'VB'),\n",
       " ('public', 'JJ'),\n",
       " ('statements', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('Tuesday', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('[', 'VB'),\n",
       " ('{', '('),\n",
       " ('``', '``'),\n",
       " ('headline', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('The', 'DT'),\n",
       " ('Interpreter', 'NNP'),\n",
       " ('Newsletter', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('summary', 'JJ'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('Understand', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('sharp', 'JJ'),\n",
       " ('insight', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('commentary', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('major', 'JJ'),\n",
       " ('news', 'NN'),\n",
       " ('stories', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('week', 'NN'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('product-code', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('INT', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('product-title', 'JJ'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('The', 'DT'),\n",
       " ('Interpreter', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " ('}', ')'),\n",
       " (',', ','),\n",
       " ('{', '('),\n",
       " ('``', '``'),\n",
       " ('headline', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('Morning', 'VBG'),\n",
       " ('Briefing', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('summary', 'JJ'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('Get', 'VB'),\n",
       " ('what', 'WP'),\n",
       " ('you', 'PRP'),\n",
       " ('need', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('know', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('start', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('day', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('United', 'NNP'),\n",
       " ('States', 'NNPS'),\n",
       " (',', ','),\n",
       " ('Canada', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('Americas', 'NNPS'),\n",
       " (',', ','),\n",
       " ('delivered', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('your', 'PRP$'),\n",
       " ('inbox', 'NN'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('product-code', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('NN', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('product-title', 'JJ'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('Morning', 'VBG'),\n",
       " ('Briefing', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('sample-url', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('http', 'NN'),\n",
       " (':', ':'),\n",
       " ('\\\\/\\\\/www.nytimes.com\\\\/newsletters\\\\/sample\\\\/morning-briefing', 'JJ'),\n",
       " ('?', '.'),\n",
       " ('pgtype=subscriptionspage', 'NN'),\n",
       " ('&', 'CC'),\n",
       " ('version=new', 'NN'),\n",
       " ('&', 'CC'),\n",
       " ('contentId=NN', 'NN'),\n",
       " ('&', 'CC'),\n",
       " ('eventName=sample', 'NN'),\n",
       " ('&', 'CC'),\n",
       " ('module=newsletter-sign-up', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('}', ')'),\n",
       " (',', ','),\n",
       " ('{', '('),\n",
       " ('``', '``'),\n",
       " ('headline', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('Breaking', 'VBG'),\n",
       " ('News', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('summary', 'JJ'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('Sign', 'NNP'),\n",
       " ('up', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('receive', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('email', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('The', 'DT'),\n",
       " ('New', 'NNP'),\n",
       " ('York', 'NNP'),\n",
       " ('Times', 'NNP'),\n",
       " ('as', 'RB'),\n",
       " ('soon', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('important', 'JJ'),\n",
       " ('news', 'NN'),\n",
       " ('breaks', 'NNS'),\n",
       " ('around', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('product-code', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('NA', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('product-title', 'JJ'),\n",
       " (\"''\", \"''\"),\n",
       " (':', ':'),\n",
       " (\"''\", \"''\"),\n",
       " ('Breaking', 'VBG'),\n",
       " ('News', 'NNP'),\n",
       " ('Alerts', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " ('}', ')'),\n",
       " (']', 'NNP'),\n",
       " ('Please', 'NNP'),\n",
       " ('verify', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " (\"'re\", 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('robot', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('clicking', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('box', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Invalid', 'NNP'),\n",
       " ('email', 'NN'),\n",
       " ('address', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Please', 'VB'),\n",
       " ('re-enter', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('You', 'PRP'),\n",
       " ('must', 'MD'),\n",
       " ('select', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('newsletter', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('subscribe', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('.', '.'),\n",
       " ('Sign', 'NNP'),\n",
       " ('Up', 'NNP'),\n",
       " ('Receive', 'NNP'),\n",
       " ('occasional', 'JJ'),\n",
       " ('updates', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('special', 'JJ'),\n",
       " ('offers', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('The', 'DT'),\n",
       " ('New', 'NNP'),\n",
       " ('York', 'NNP'),\n",
       " ('Times', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('products', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('services', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('for', 'IN'),\n",
       " ('subscribing', 'VBG'),\n",
       " ('.', '.'),\n",
       " ('An', 'DT'),\n",
       " ('error', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('occurred', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('Please', 'NNP'),\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mr.', 23),\n",
       " ('Obama', 16),\n",
       " ('story', 9),\n",
       " ('China', 9),\n",
       " ('White', 9),\n",
       " ('House', 8),\n",
       " ('Continue', 8),\n",
       " ('Xi', 8),\n",
       " ('Advertisement', 8),\n",
       " ('President', 6),\n",
       " ('time', 6),\n",
       " ('president', 6),\n",
       " ('news', 6),\n",
       " ('officials', 5),\n",
       " ('leaders', 5),\n",
       " ('deal', 4),\n",
       " ('meeting', 4),\n",
       " ('part', 4),\n",
       " ('questions', 4),\n",
       " ('email', 3)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = [token for (token,tag) in tagged if  tag.startswith('NN')]\n",
    "fd_nyt = nltk.FreqDist(nouns)\n",
    "fd_nyt.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chinese', 10),\n",
       " ('main', 9),\n",
       " ('summary', 3),\n",
       " ('American', 3),\n",
       " ('product-title', 3),\n",
       " ('other', 3),\n",
       " ('public', 3),\n",
       " ('former', 2),\n",
       " ('less', 2),\n",
       " ('major', 2),\n",
       " ('prosperous', 2),\n",
       " ('willing', 2),\n",
       " ('illuminated', 1),\n",
       " ('last', 1),\n",
       " ('easier', 1),\n",
       " ('broader', 1),\n",
       " ('aware', 1),\n",
       " ('re-enter', 1),\n",
       " ('quiet', 1),\n",
       " ('vivid', 1)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjectives = [token for (token,tag) in tagged if  tag.startswith('JJ')]\n",
    "fd_nyt = nltk.FreqDist(adjectives)\n",
    "fd_nyt.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Primitive sentiment analysis\n",
    "\n",
    "Adjectives are known to be the primary carriers of sentiment. So now let's pick a piece of text and identify the adjectives that appear in the text and their sentiment score. For that, we will use the  SentiWordNet, a lexical resource for opinion mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<breakdown.n.03: PosScore=0.0 NegScore=0.25>\n"
     ]
    }
   ],
   "source": [
    "# See http://www.nltk.org/_modules/nltk/corpus/reader/sentiwordnet.html for the documentation\n",
    "\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "print(swn.senti_synset('breakdown.n.03'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's analyze a review text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Amazon review for Samsung Galaxy S5, White 16GB\n",
    "# http://www.amazon.com/review/R3UULR1IWEUS4I/ref=cm_cr_dp_title?ie=UTF8&ASIN=B00IZ1X21K&nodeID=2335752011&store=wireless\n",
    "\n",
    "\n",
    "content = u'''\n",
    "First off, I am not a professional reviewer, nor am I employed or compensated by Samsung or any other company. Instead of boring you with facts - which you can find anywhere on the Net - I will just give you some real-world impressions on how it looks, feels, and runs. With that out of the way, let's get to the point and the nitty gritty, shall we?\n",
    "\n",
    "* THE SCREEN - that is the very first thing you will notice when you look at the S5. Samsung has found its niche with AMOLED screens, which are BRIGHT & SATURATED. Everything almost literally jumps out at you, and sometimes even too much so. I had to switch to the \"natural\" setting, as the \"vivid\" and even \"standard\" profiles are too saturated(and FAKE) for me. It's better as a demo unit to draw you in, but for everyday use, I recommend switching to the natural profile.\n",
    "FACTS: The Galaxy S5 has a 5.1-inch Super AMOLED capacitive touchscreen with Full HD resolution - 1080 x 1920 pixels or ~432 ppi pixel density, plus Gorilla Glass 3 to protect the screen from scratches.\n",
    "\n",
    "* The Look - the S5 has a more squared-off edges look than the S4, which is more squared off than the S3, but all three are not as angular as the S2. In terms of roundness-to square-ness, it goes from the S3 - S4 - S5 - S2 (the original S just looks like an iPhone 3GS). Check out my images for an easier comparison. The S5 is the tallest and widest, but not the thickest of the Galaxy S's. The best thing I can say about this is it's an evolution. Beauty is subjective, so judge for yourself. The front side is almost the same as any other Galaxy phone: You have the physical Home button, flanked by the \"back\" and \"menu\" capacitive buttons. Probably the most improved aspect of the design is in its functionality - it is now dust-proof, and water-proof up to 3 feet!\n",
    "FACTS: The dimensions are 5.59\" x 2.85\" x 0.32\"(142cm x 72.5cm x 8.1cm), and weighs 5.11oz(145g).\n",
    "\n",
    "* The Feel - Samsung has taken a lot of flack for making the Galaxy S line so cheap looking and feeling with its plastic bodies, for being the top Android phone maker. HTC has been known to have the best craftsmanship with their all-metal One phones. Perhaps Samsung feel they are so dominant that they don't have to spend more to mass-produce metal phones, but since they don't want to come off as too arrogant, so their compromise is a dimpled, faux-rubber backside like the Nexus 7(2012) and its very own Galaxy Note 3. It definitely gives a better feel - it doesn't slip and slide in your hands or pockets anymore - but it cannot compare to the feel and craftsmanship of the HTC One(both the m7 and m8). It is on the right track though, so let's hope that rumored luxury \"F\" line or next year's S6 will continue to get better.\n",
    "\n",
    "* How it Runs - This phone is fast, fast, FAST! With a 2.5gHz Snapdragon 801, it has the fastest processor out there right now. It terms of real speed, I cannot say if it is faster than the HTC One m8 or the Sony Xperia Z2, but it is definitely up there. When you touch an app icon to launch it, it launches nearly instantly. To really see how this phone flies, just open the gallery app and scroll through all your photos and you'll see what I mean. Usually the gallery is where most phones stutter as it tries to load all your photos and albums - but NOT the S5!\n",
    "\n",
    "* The Camera - FINALLY! Samsung has decided to make a decent camera, and not just as an afterthought. This 16mp camera is really awesome, so much better than the S4. I would always get washed out images with my S3/S4/Note 2, but with the S5, it actually looks like it's from a decent point-and-shoot dedicated camera with crisp, bright, and saturated images. Low-light shooting is also vastly improved, although not as good as the new HTC One m8. 16mp means 5312 x 2988 -resolution images, so you can actually blow them up or crop them down without fearing the dreaded pixelation monster. There are a myriad of other cool and useful camera features that I will save for you to find out(like macro and \"Google Street View\" modes :]). And lastly, the focus is quick, quick, QUICK! Nearly instantaneous focus allows you to capture those hard-to-capture moments easier. A definitely thumbs up to Samsung for paying attention to the camera and its functions.\n",
    "\n",
    "* Software - I'm still trying to figure out everything, as there is A LOT of stuff under the hood. Samsung's TouchWiz user interface this time around is A LOT less intrusive though, as much as can be without being totally stock Android, I guess. The layout and iconography are flatter and simpler, and for the better in my view. There is also a new sensor on the back, just beneath the camera lens. It is a heart-rate monitor/pedometer, and it comes with its own health app called S Health. There is a new battery-saving mode which can save you precious minutes when you're caught in a bind. All in all, I think this version is a lot nicer-looking, more responsive, and better than the precious S phones.\n",
    "\n",
    "The ultimate question is whether this phone is a worthy upgrade over the S4. As my review title suggests, it is an evolution, an incremental upgrade over the S4. So with that said I cannot whole-heartedly recommend it if you already have a good phone, or even over the S4. But I do feel this upgrade is more vast and much better than from the S3 to the S4, so in that sense Samsung has done a much better job this year. If you are switching from an older phone that was made at least 2 years ago, then I would tell you jump right in and try the S5 - it will not disappoint you. But for those with already a good phone, and/or say you just finished year one of your 2-year contract, then I would say think hard before you make the leap. For my money, I think the Note 4 and S6 will be the bigger upgrades more worth waiting for.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(content)\n",
    "text = nltk.Text(tokens)\n",
    "tagged = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['professional', 'other', 'Net', 'real-world', 'nitty', 'first', 'much', 'natural', 'standard', 'everyday', 'natural', '5.1-inch', 'ppi', 'squared-off', 'angular', 'roundness-to', 'original', 'easier', 'widest', 'best', 'subjective', 'front', 'same', 'other', 'physical', 'capacitive', 'improved', 'dust-proof', 'water-proof', 'x', 'cheap', 'top', 'best', 'all-metal', 'dominant', 'more', 'arrogant', 'dimpled', 'faux-rubber', 'own', 'better', 'right', 'next', 'fastest', 'real', 'app', 'decent', 'awesome', 'better', 'decent', 'Low-light', 'good', 'new', 'dreaded', 'other', 'useful', 'quick', 'quick', 'instantaneous', 'hard-to-capture', 'intrusive', 'much', 'better', 'new', 'heart-rate', 'own', 'new', 'precious', 'nicer-looking', 'responsive', 'better', 'precious', 'ultimate', 'worthy', 'incremental', 'good', 'vast', 'better', 'better', 'older', 'least', 'good', '2-year', 'hard', 'bigger', 'worth']\n"
     ]
    }
   ],
   "source": [
    "# Let's keep the adjectives only\n",
    "adjectives = [word for (word , pos_tag) in tagged if pos_tag.startswith('JJ')]\n",
    "print(adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('professional', SentiSynset('professional.a.01')), ('other', SentiSynset('other.a.01')), ('Net', SentiSynset('net.a.01')), ('first', SentiSynset('first.a.01')), ('much', SentiSynset('much.a.01')), ('natural', SentiSynset('natural.a.01')), ('standard', SentiSynset('standard.a.01')), ('everyday', SentiSynset('everyday.s.01')), ('natural', SentiSynset('natural.a.01')), ('angular', SentiSynset('angular.a.01')), ('original', SentiSynset('original.s.01')), ('easier', SentiSynset('easy.a.01')), ('widest', SentiSynset('wide.a.01')), ('best', SentiSynset('best.a.01')), ('subjective', SentiSynset('subjective.a.01')), ('front', SentiSynset('front.a.01')), ('same', SentiSynset('same.a.01')), ('other', SentiSynset('other.a.01')), ('physical', SentiSynset('physical.a.01')), ('capacitive', SentiSynset('capacitive.a.01')), ('improved', SentiSynset('improved.a.01')), ('x', SentiSynset('ten.s.01')), ('cheap', SentiSynset('cheap.a.01')), ('top', SentiSynset('top.a.01')), ('best', SentiSynset('best.a.01')), ('all-metal', SentiSynset('all-metal.s.01')), ('dominant', SentiSynset('dominant.a.01')), ('more', SentiSynset('more.a.01')), ('arrogant', SentiSynset('arrogant.s.01')), ('own', SentiSynset('own.s.01')), ('better', SentiSynset('better.a.01')), ('right', SentiSynset('right.a.01')), ('next', SentiSynset('following.s.02')), ('fastest', SentiSynset('fast.a.01')), ('real', SentiSynset('real.a.01')), ('decent', SentiSynset('decent.s.01')), ('awesome', SentiSynset('amazing.s.02')), ('better', SentiSynset('better.a.01')), ('decent', SentiSynset('decent.s.01')), ('good', SentiSynset('good.a.01')), ('new', SentiSynset('new.a.01')), ('dreaded', SentiSynset('awful.s.02')), ('other', SentiSynset('other.a.01')), ('useful', SentiSynset('useful.a.01')), ('quick', SentiSynset('quick.s.01')), ('quick', SentiSynset('quick.s.01')), ('instantaneous', SentiSynset('instantaneous.s.01')), ('intrusive', SentiSynset('intrusive.a.01')), ('much', SentiSynset('much.a.01')), ('better', SentiSynset('better.a.01')), ('new', SentiSynset('new.a.01')), ('own', SentiSynset('own.s.01')), ('new', SentiSynset('new.a.01')), ('precious', SentiSynset('cherished.s.01')), ('responsive', SentiSynset('responsive.a.01')), ('better', SentiSynset('better.a.01')), ('precious', SentiSynset('cherished.s.01')), ('ultimate', SentiSynset('ultimate.a.01')), ('worthy', SentiSynset('worthy.a.01')), ('incremental', SentiSynset('incremental.s.01')), ('good', SentiSynset('good.a.01')), ('vast', SentiSynset('huge.s.01')), ('better', SentiSynset('better.a.01')), ('better', SentiSynset('better.a.01')), ('older', SentiSynset('aged.s.01')), ('least', SentiSynset('least.a.01')), ('good', SentiSynset('good.a.01')), ('hard', SentiSynset('difficult.a.01')), ('bigger', SentiSynset('bigger.s.01')), ('worth', SentiSynset('deserving.s.01'))]\n"
     ]
    }
   ],
   "source": [
    "# Now we want to use WordNet and eliminate the words that do not appear in our lexicon\n",
    "# Since we do not have much of information for further disambiguation, we will keep only the \n",
    "# most popular interpretation (list element 0) if there are multiple ones\n",
    "resolved_adjectives = [(w, list(swn.senti_synsets(w, 'a'))[0]) \n",
    "                       for w in adjectives \n",
    "                       if len(list(swn.senti_synsets(w, 'a')))>0]\n",
    "print(resolved_adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: professional\n",
      "Synset: <professional.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: other\n",
      "Synset: <other.a.01: PosScore=0.0 NegScore=0.625>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.625\n",
      "Objectivity score: 0.375\n",
      "======================================\n",
      "Word: Net\n",
      "Synset: <net.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: first\n",
      "Synset: <first.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: much\n",
      "Synset: <much.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: natural\n",
      "Synset: <natural.a.01: PosScore=0.25 NegScore=0.0>\n",
      "Pos score: 0.25\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.75\n",
      "======================================\n",
      "Word: standard\n",
      "Synset: <standard.a.01: PosScore=0.375 NegScore=0.375>\n",
      "Pos score: 0.375\n",
      "Neg score: 0.375\n",
      "Objectivity score: 0.25\n",
      "======================================\n",
      "Word: everyday\n",
      "Synset: <everyday.s.01: PosScore=0.125 NegScore=0.0>\n",
      "Pos score: 0.125\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.875\n",
      "======================================\n",
      "Word: natural\n",
      "Synset: <natural.a.01: PosScore=0.25 NegScore=0.0>\n",
      "Pos score: 0.25\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.75\n",
      "======================================\n",
      "Word: angular\n",
      "Synset: <angular.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: original\n",
      "Synset: <original.s.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: easier\n",
      "Synset: <easy.a.01: PosScore=0.625 NegScore=0.25>\n",
      "Pos score: 0.625\n",
      "Neg score: 0.25\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: widest\n",
      "Synset: <wide.a.01: PosScore=0.25 NegScore=0.125>\n",
      "Pos score: 0.25\n",
      "Neg score: 0.125\n",
      "Objectivity score: 0.625\n",
      "======================================\n",
      "Word: best\n",
      "Synset: <best.a.01: PosScore=0.75 NegScore=0.0>\n",
      "Pos score: 0.75\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.25\n",
      "======================================\n",
      "Word: subjective\n",
      "Synset: <subjective.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: front\n",
      "Synset: <front.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: same\n",
      "Synset: <same.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: other\n",
      "Synset: <other.a.01: PosScore=0.0 NegScore=0.625>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.625\n",
      "Objectivity score: 0.375\n",
      "======================================\n",
      "Word: physical\n",
      "Synset: <physical.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: capacitive\n",
      "Synset: <capacitive.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: improved\n",
      "Synset: <improved.a.01: PosScore=0.375 NegScore=0.0>\n",
      "Pos score: 0.375\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.625\n",
      "======================================\n",
      "Word: x\n",
      "Synset: <ten.s.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: cheap\n",
      "Synset: <cheap.a.01: PosScore=0.0 NegScore=0.25>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.25\n",
      "Objectivity score: 0.75\n",
      "======================================\n",
      "Word: top\n",
      "Synset: <top.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: best\n",
      "Synset: <best.a.01: PosScore=0.75 NegScore=0.0>\n",
      "Pos score: 0.75\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.25\n",
      "======================================\n",
      "Word: all-metal\n",
      "Synset: <all-metal.s.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: dominant\n",
      "Synset: <dominant.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: more\n",
      "Synset: <more.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: arrogant\n",
      "Synset: <arrogant.s.01: PosScore=0.5 NegScore=0.375>\n",
      "Pos score: 0.5\n",
      "Neg score: 0.375\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: own\n",
      "Synset: <own.s.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: better\n",
      "Synset: <better.a.01: PosScore=0.875 NegScore=0.0>\n",
      "Pos score: 0.875\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: right\n",
      "Synset: <right.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: next\n",
      "Synset: <following.s.02: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: fastest\n",
      "Synset: <fast.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: real\n",
      "Synset: <real.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: decent\n",
      "Synset: <decent.s.01: PosScore=0.875 NegScore=0.0>\n",
      "Pos score: 0.875\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: awesome\n",
      "Synset: <amazing.s.02: PosScore=0.875 NegScore=0.125>\n",
      "Pos score: 0.875\n",
      "Neg score: 0.125\n",
      "Objectivity score: 0.0\n",
      "======================================\n",
      "Word: better\n",
      "Synset: <better.a.01: PosScore=0.875 NegScore=0.0>\n",
      "Pos score: 0.875\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: decent\n",
      "Synset: <decent.s.01: PosScore=0.875 NegScore=0.0>\n",
      "Pos score: 0.875\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: good\n",
      "Synset: <good.a.01: PosScore=0.75 NegScore=0.0>\n",
      "Pos score: 0.75\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.25\n",
      "======================================\n",
      "Word: new\n",
      "Synset: <new.a.01: PosScore=0.375 NegScore=0.0>\n",
      "Pos score: 0.375\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.625\n",
      "======================================\n",
      "Word: dreaded\n",
      "Synset: <awful.s.02: PosScore=0.0 NegScore=0.625>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.625\n",
      "Objectivity score: 0.375\n",
      "======================================\n",
      "Word: other\n",
      "Synset: <other.a.01: PosScore=0.0 NegScore=0.625>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.625\n",
      "Objectivity score: 0.375\n",
      "======================================\n",
      "Word: useful\n",
      "Synset: <useful.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: quick\n",
      "Synset: <quick.s.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: quick\n",
      "Synset: <quick.s.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: instantaneous\n",
      "Synset: <instantaneous.s.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: intrusive\n",
      "Synset: <intrusive.a.01: PosScore=0.125 NegScore=0.5>\n",
      "Pos score: 0.125\n",
      "Neg score: 0.5\n",
      "Objectivity score: 0.375\n",
      "======================================\n",
      "Word: much\n",
      "Synset: <much.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: better\n",
      "Synset: <better.a.01: PosScore=0.875 NegScore=0.0>\n",
      "Pos score: 0.875\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: new\n",
      "Synset: <new.a.01: PosScore=0.375 NegScore=0.0>\n",
      "Pos score: 0.375\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.625\n",
      "======================================\n",
      "Word: own\n",
      "Synset: <own.s.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: new\n",
      "Synset: <new.a.01: PosScore=0.375 NegScore=0.0>\n",
      "Pos score: 0.375\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.625\n",
      "======================================\n",
      "Word: precious\n",
      "Synset: <cherished.s.01: PosScore=0.625 NegScore=0.25>\n",
      "Pos score: 0.625\n",
      "Neg score: 0.25\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: responsive\n",
      "Synset: <responsive.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: better\n",
      "Synset: <better.a.01: PosScore=0.875 NegScore=0.0>\n",
      "Pos score: 0.875\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: precious\n",
      "Synset: <cherished.s.01: PosScore=0.625 NegScore=0.25>\n",
      "Pos score: 0.625\n",
      "Neg score: 0.25\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: ultimate\n",
      "Synset: <ultimate.a.01: PosScore=0.0 NegScore=0.125>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.125\n",
      "Objectivity score: 0.875\n",
      "======================================\n",
      "Word: worthy\n",
      "Synset: <worthy.a.01: PosScore=0.875 NegScore=0.0>\n",
      "Pos score: 0.875\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: incremental\n",
      "Synset: <incremental.s.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: good\n",
      "Synset: <good.a.01: PosScore=0.75 NegScore=0.0>\n",
      "Pos score: 0.75\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.25\n",
      "======================================\n",
      "Word: vast\n",
      "Synset: <huge.s.01: PosScore=0.0 NegScore=0.125>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.125\n",
      "Objectivity score: 0.875\n",
      "======================================\n",
      "Word: better\n",
      "Synset: <better.a.01: PosScore=0.875 NegScore=0.0>\n",
      "Pos score: 0.875\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: better\n",
      "Synset: <better.a.01: PosScore=0.875 NegScore=0.0>\n",
      "Pos score: 0.875\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.125\n",
      "======================================\n",
      "Word: older\n",
      "Synset: <aged.s.01: PosScore=0.5 NegScore=0.0>\n",
      "Pos score: 0.5\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.5\n",
      "======================================\n",
      "Word: least\n",
      "Synset: <least.a.01: PosScore=0.0 NegScore=0.0>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.0\n",
      "Objectivity score: 1.0\n",
      "======================================\n",
      "Word: good\n",
      "Synset: <good.a.01: PosScore=0.75 NegScore=0.0>\n",
      "Pos score: 0.75\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.25\n",
      "======================================\n",
      "Word: hard\n",
      "Synset: <difficult.a.01: PosScore=0.0 NegScore=0.75>\n",
      "Pos score: 0.0\n",
      "Neg score: 0.75\n",
      "Objectivity score: 0.25\n",
      "======================================\n",
      "Word: bigger\n",
      "Synset: <bigger.s.01: PosScore=0.125 NegScore=0.0>\n",
      "Pos score: 0.125\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.875\n",
      "======================================\n",
      "Word: worth\n",
      "Synset: <deserving.s.01: PosScore=0.25 NegScore=0.0>\n",
      "Pos score: 0.25\n",
      "Neg score: 0.0\n",
      "Objectivity score: 0.75\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "# SentiWordNet assigns to each synset of WordNet three\n",
    "# sentiment scores: positivity, negativity, and objectivity.\n",
    "\n",
    "for (w,a) in resolved_adjectives:\n",
    "    print(\"Word:\", w)\n",
    "    print(\"Synset:\", a)\n",
    "    print(\"Pos score:\",  a.pos_score())\n",
    "    print(\"Neg score:\",  a.neg_score())\n",
    "    print(\"Objectivity score:\",  a.obj_score())\n",
    "    print(\"======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['real-world', 'nitty', '5.1-inch', 'ppi', 'squared-off', 'roundness-to', 'dust-proof', 'water-proof', 'dimpled', 'faux-rubber', 'app', 'Low-light', 'hard-to-capture', 'heart-rate', 'nicer-looking', '2-year']\n"
     ]
    }
   ],
   "source": [
    "# But let's take a look at what we rejected\n",
    "rejected_adjectives = [w for w in adjectives if len(list(swn.senti_synsets(w, 'a')))==0]\n",
    "print(rejected_adjectives)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Perhaps we would also like to figure out what the adjectives in the text refer to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "professional reviewer\n",
      "other company\n",
      "nitty gritty\n",
      "first thing\n",
      "everyday use\n",
      "natural profile\n",
      "ppi pixel\n",
      "roundness-to square-ness\n",
      "front side\n",
      "improved aspect\n",
      "water-proof up\n",
      "faux-rubber backside\n",
      "right track\n",
      "next year\n",
      "real speed\n",
      "app icon\n",
      "decent camera\n",
      "decent point-and-shoot\n",
      "Low-light shooting\n",
      "dreaded pixelation\n",
      "other cool\n",
      "useful camera\n",
      "instantaneous focus\n",
      "intrusive though\n",
      "new sensor\n",
      "heart-rate monitor/pedometer\n",
      "own health\n",
      "new battery-saving\n",
      "ultimate question\n",
      "worthy upgrade\n",
      "incremental upgrade\n",
      "good phone\n",
      "good phone\n",
      "2-year contract\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(tagged)):\n",
    "    current_word = tagged[i][0]\n",
    "    current_pos = tagged[i][1]\n",
    "    if current_pos == 'NN':\n",
    "        previous_word = tagged[i-1][0]\n",
    "        previous_pos = tagged[i-1][1]\n",
    "        if previous_pos == 'JJ':\n",
    "            print(previous_word + \" \" + current_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Excercise 1\n",
    "\n",
    "Try a new text with this type of sentiment analysis. Let's figure out what works and what does not\n",
    "\n",
    "#### Exercise 2\n",
    "\n",
    "Instead of adjectives-nouns, we can instead use adverbs and verbs (e.g., \"works nicely\"). Let's modify the code above to extract patterns involving verbs and adverbs\n",
    "\n",
    "#### Exercise 3\n",
    "\n",
    "How can you modify the code to find more patterns, instead of just JJ-NN (adjective followed by noun)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Named Entity Recognition\n",
    "\n",
    "Named entities are definite noun phrases that refer to specific types of individuals, such as organizations, persons, dates, and so on. Here is a list of some commonly used Named Entities:\n",
    " \n",
    "* ORGANIZATION\t(e.g., Georgia-Pacific Corp., WHO)\n",
    "* PERSON\t(e.g., Eddy Bonte, President Obama)\n",
    "* LOCATION\t(e.g., Murray River, Mount Everest)\n",
    "* DATE\t(e.g., June, 2008-06-29)\n",
    "* TIME\t(e.g., two fifty a m, 1:30 p.m.)\n",
    "* MONEY\t(e.g., 175 million Canadian Dollars, GBP 10.40)\n",
    "* PERCENT\t(e.g., twenty pct, 18.75 %)\n",
    "* FACILITY\t(e.g., Washington Monument, Stonehenge)\n",
    "* GPE\t(e.g., South East Asia, Midlothian)\n",
    "\n",
    "The goal of a named entity recognition (NER) system is to identify all textual mentions of the named entities. This can be broken down into two sub-tasks: identifying the boundaries of the NE, and identifying its type.\n",
    "\n",
    "NLTK provides a module that has already been trained to recognize named entities, accessed with the function nltk.ne_chunk(). If we set the parameter `binary=True`, then named entities are just tagged as NE; otherwise, the classifier adds category labels such as PERSON, ORGANIZATION, and GPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "raw = u'''\n",
    "Morgan Stanley received a long-awaited ratings upgrade from Moody’s Investors Service, an endorsement of the firm’s strategy shift and a move that could help the bank pick up new trading clients.\n",
    "\n",
    "In raising Morgan Stanley’s rating two notches, Moody’s determined that strategic changes at the investment bank in recent years have resulted in a safer business model and improved profitability.\n",
    "\n",
    "Goldman Sachs Group Inc., Bank of America Corp. and Citigroup Inc. received one-notch upgrades as part of a broader Moody’s review of the largest global banks.\n",
    "\n",
    "The actions were in part a reversal of the downgrades Moody’s issued to several banks in 2012. Moody’s at that time found that the European sovereign-debt crisis and other macroeconomic and regulatory factors were crimping banks’ profitability.\n",
    "\n",
    "Since the downgrade, Morgan Stanley Chairman and Chief Executive James Gorman has continued to push the bank away from volatile activities such as trading while expanding in businesses such as wealth management that generate earnings more steadily. Moody’s said that those switches to its business mix, as well as changes to its funding that would lead to fewer losses for creditors if the bank were to fail, led it to upgrade Morgan Stanley’s debt by two notches from Baa2 to A3.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Morgan/NNP)\n",
      "  (PERSON Stanley/NNP)\n",
      "  received/VBD\n",
      "  a/DT\n",
      "  long-awaited/JJ\n",
      "  ratings/NNS\n",
      "  upgrade/NN\n",
      "  from/IN\n",
      "  (ORGANIZATION Moody’s/NNP Investors/NNPS Service/NNP)\n",
      "  ,/,\n",
      "  an/DT\n",
      "  endorsement/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  firm’s/NN\n",
      "  strategy/NN\n",
      "  shift/NN\n",
      "  and/CC\n",
      "  a/DT\n",
      "  move/NN\n",
      "  that/WDT\n",
      "  could/MD\n",
      "  help/VB\n",
      "  the/DT\n",
      "  bank/NN\n",
      "  pick/VB\n",
      "  up/RP\n",
      "  new/JJ\n",
      "  trading/NN\n",
      "  clients/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  In/IN\n",
      "  raising/VBG\n",
      "  (PERSON Morgan/NNP)\n",
      "  Stanley’s/NNP\n",
      "  rating/NN\n",
      "  two/CD\n",
      "  notches/NNS\n",
      "  ,/,\n",
      "  (PERSON Moody’s/NNP)\n",
      "  determined/VBD\n",
      "  that/IN\n",
      "  strategic/JJ\n",
      "  changes/NNS\n",
      "  at/IN\n",
      "  the/DT\n",
      "  investment/NN\n",
      "  bank/NN\n",
      "  in/IN\n",
      "  recent/JJ\n",
      "  years/NNS\n",
      "  have/VBP\n",
      "  resulted/VBN\n",
      "  in/IN\n",
      "  a/DT\n",
      "  safer/NN\n",
      "  business/NN\n",
      "  model/NN\n",
      "  and/CC\n",
      "  improved/VBN\n",
      "  profitability/NN\n",
      "  ./.)\n",
      "(S\n",
      "  (PERSON Goldman/NNP)\n",
      "  (PERSON Sachs/NNP Group/NNP Inc./NNP)\n",
      "  ,/,\n",
      "  (ORGANIZATION Bank/NNP)\n",
      "  of/IN\n",
      "  (ORGANIZATION America/NNP Corp./NNP)\n",
      "  and/CC\n",
      "  (ORGANIZATION Citigroup/NNP Inc./NNP)\n",
      "  received/VBD\n",
      "  one-notch/JJ\n",
      "  upgrades/NNS\n",
      "  as/IN\n",
      "  part/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  broader/JJR\n",
      "  Moody’s/NNP\n",
      "  review/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  largest/JJS\n",
      "  global/JJ\n",
      "  banks/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  The/DT\n",
      "  actions/NNS\n",
      "  were/VBD\n",
      "  in/IN\n",
      "  part/NN\n",
      "  a/DT\n",
      "  reversal/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  downgrades/NNS\n",
      "  Moody’s/NNP\n",
      "  issued/VBD\n",
      "  to/TO\n",
      "  several/JJ\n",
      "  banks/NNS\n",
      "  in/IN\n",
      "  2012/CD\n",
      "  ./.)\n",
      "(S\n",
      "  Moody’s/NN\n",
      "  at/IN\n",
      "  that/DT\n",
      "  time/NN\n",
      "  found/VBD\n",
      "  that/IN\n",
      "  the/DT\n",
      "  (GPE European/JJ)\n",
      "  sovereign-debt/NN\n",
      "  crisis/NN\n",
      "  and/CC\n",
      "  other/JJ\n",
      "  macroeconomic/JJ\n",
      "  and/CC\n",
      "  regulatory/JJ\n",
      "  factors/NNS\n",
      "  were/VBD\n",
      "  crimping/VBG\n",
      "  banks’/JJ\n",
      "  profitability/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Since/IN\n",
      "  the/DT\n",
      "  downgrade/NN\n",
      "  ,/,\n",
      "  (PERSON Morgan/NNP Stanley/NNP Chairman/NNP)\n",
      "  and/CC\n",
      "  Chief/NNP\n",
      "  Executive/NNP\n",
      "  (PERSON James/NNP Gorman/NNP)\n",
      "  has/VBZ\n",
      "  continued/VBN\n",
      "  to/TO\n",
      "  push/VB\n",
      "  the/DT\n",
      "  bank/NN\n",
      "  away/RB\n",
      "  from/IN\n",
      "  volatile/JJ\n",
      "  activities/NNS\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  trading/NN\n",
      "  while/IN\n",
      "  expanding/VBG\n",
      "  in/IN\n",
      "  businesses/NNS\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  wealth/NN\n",
      "  management/NN\n",
      "  that/WDT\n",
      "  generate/VBP\n",
      "  earnings/NNS\n",
      "  more/RBR\n",
      "  steadily/RB\n",
      "  ./.)\n",
      "(S\n",
      "  (PERSON Moody’s/NNP)\n",
      "  said/VBD\n",
      "  that/IN\n",
      "  those/DT\n",
      "  switches/NNS\n",
      "  to/TO\n",
      "  its/PRP$\n",
      "  business/NN\n",
      "  mix/NN\n",
      "  ,/,\n",
      "  as/RB\n",
      "  well/RB\n",
      "  as/IN\n",
      "  changes/NNS\n",
      "  to/TO\n",
      "  its/PRP$\n",
      "  funding/NN\n",
      "  that/WDT\n",
      "  would/MD\n",
      "  lead/VB\n",
      "  to/TO\n",
      "  fewer/JJR\n",
      "  losses/NNS\n",
      "  for/IN\n",
      "  creditors/NNS\n",
      "  if/IN\n",
      "  the/DT\n",
      "  bank/NN\n",
      "  were/VBD\n",
      "  to/TO\n",
      "  fail/VB\n",
      "  ,/,\n",
      "  led/VBD\n",
      "  it/PRP\n",
      "  to/TO\n",
      "  upgrade/VB\n",
      "  (PERSON Morgan/NNP)\n",
      "  Stanley’s/NNP\n",
      "  debt/NN\n",
      "  by/IN\n",
      "  two/CD\n",
      "  notches/NNS\n",
      "  from/IN\n",
      "  (GPE Baa2/JJ)\n",
      "  to/TO\n",
      "  (GPE A3/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(raw)\n",
    "sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "\n",
    "for sent in sentences:\n",
    "    named_entities = nltk.ne_chunk(sent, binary=False)\n",
    "    print(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
